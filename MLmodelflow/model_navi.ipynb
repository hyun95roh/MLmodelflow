{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./ml_map.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excel\n",
      "For predicting categorical variable, there are two branches: Clustering | Classification \n",
      "For clustering : \n",
      " If you have predefined # of cluster: \n",
      "  1) large sample size >= 100k -> KMeans, Spectral, GMM \n",
      "  2) size <100k -> MiniBatch-Kmeans \n",
      " If you don't have predefined # of cluster:\n",
      "   1) size >= 100k -> No recommendable model. You should find the fit model by yourself. \n",
      " 2) size < 100k -> MeanShift, VBGMM \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Try MiniBatch Kmeans clustering'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "# Read data \n",
    "directory = '../../jupyter/DSCI_552/homework-2-hyun95roh/data/CCPP/Folds5x2_pp.xlsx'\n",
    "extension = directory[directory.rfind('.')+1:]\n",
    "if extension in ['xlsx','xls','xlsb','xlsm']: \n",
    "    extension = 'excel' \n",
    "print(extension)\n",
    "read_data = eval(f'pd.read_{extension}(\"{directory}\")') \n",
    "\n",
    "\n",
    "def modelflow(data):\n",
    "    sample_size = len(data)  \n",
    "    if sample_size <50 : \n",
    "        return('Your sample size looks insufficient. Gather more data')\n",
    "    else: \n",
    "        response = input(\"Enter 'Y' either 'N': Are you predicting categorical variable?\")\n",
    "        if response.upper() in ['Y','YES'] :\n",
    "            print(\"For predicting categorical variable, there are two branches: Clustering | Classification \")\n",
    "\n",
    "            response_a1 = input(\"Enter 'Y'or 'N': Do you have labeled response?\" ) \n",
    "            #  Y:Classification \n",
    "            if response_a1.upper() in ['Y','YES'] : \n",
    "                print(\"For classification : \\n\" ,\n",
    "                      \"1) large sample size >= 100k -> SGD \\n\", \n",
    "                      \"2) sample size < 100k -> SVC, NaiveBayes, KNN \\n\") \n",
    "                if sample_size >= 100000 :\n",
    "                    #SGD classificer -> Kernel Approximation  \n",
    "                    return(\"Try Stochastic Gradient Descent(SGD) classifier. If it still not working, try Kernel Approximation\")\n",
    "                else : \n",
    "                    #Linear SVC  -> (text)Naive Bayes | (non-text) KNN -> SVC or Ensemble \n",
    "                    return(\"Linear Support Vector Classifier(SVC) is recommended. If it does not work and if you are working with text data, try Naive Bayes. If you are not dealing with text data then try KNN classifier. If still does not work well, try SVC or Ensemble classifiers \")\n",
    "            else : # N: Clustering \n",
    "                response_a2 = input(\"Enter 'Y'or 'N': Is Number of categories known?\")   \n",
    "                print(\"For clustering : \\n\", \n",
    "                      \"If you have predefined # of cluster: \\n\",\n",
    "                      \" 1) large sample size >= 100k -> KMeans, Spectral, GMM \\n\" ,\n",
    "                      \" 2) size <100k -> MiniBatch-Kmeans \\n\",\n",
    "                      \"If you don't have predefined # of cluster:\\n \",\n",
    "                      \" 1) size >= 100k -> No recommendable model. You should find the fit model by yourself. \\n\",\n",
    "                      \" 2) size < 100k -> MeanShift, VBGMM \\n\"  )\n",
    "                if response_a2.upper() in ['Y','YES'] :\n",
    "                    if sample_size >=100000: \n",
    "                        \n",
    "                        return('Try Kmeans clustering. If it does not work, try Spectral clustering or GMM')     \n",
    "                    else :\n",
    "                        return('Try MiniBatch Kmeans clustering')\n",
    "                \n",
    "                else : # Case when the # of cluster is not predefined.  \n",
    "                    if sample_size >= 100000: \n",
    "                        return('Tough luck...')\n",
    "                    else: \n",
    "                        return('Try MeanShift or VBGMM.') \n",
    "\n",
    "            \n",
    "        elif response.upper() in ['N','NO'] : \n",
    "            print(\"Now your model is heading to: Regression | Dimension Reduction.\") \n",
    "\n",
    "            response_b1 = input(\"Enter 'Y' or 'N': Are you predicting quantitative values?\") #Y: Regression / N: Dim Reduction\n",
    "            if response_b1.upper() in ['Y','YES']:  \n",
    "                print(\"For regression: \\n\", \n",
    "                      \"1) Sample size >= 100k -> SGD \\n\", \n",
    "                      \"2) size < 100k -> Allow regularization has feature selection effect? \\n\",\n",
    "                        \" Yes --> L1-reg, Elastic net \\n\", \n",
    "                        \" No --> L2-reg, SVR, Ensemble. \\n\")\n",
    "                if sample_size >= 100000: \n",
    "                    return(\"Try SGD regressor\") \n",
    "                else : \n",
    "                    response_b1_a = input(\"Enter 'N' or 'Y': Do you want to allow feature selection through Regularization?\")\n",
    "                    if response_b1_a.upper() in ['Y','YES']: \n",
    "                        return('Try regression with L1(Lasso)-regularization or Elsatic Net.')\n",
    "                    else : \n",
    "                        return('Try regression with L2(Ridge)-regularization or Support Vector Regression(SVR) with linear kernel. If still not working, try Ensemble Regressor or SVR with rbf kernel.')\n",
    "\n",
    "            else : \n",
    "                response_b2 = input(\"Enter 'Y' or 'N': Are you running dimensionality reduction?\")  \n",
    "                if response_b2 in ['Y','YES']: \n",
    "                    print(\"For Dimensionality reduction: \\n\", \n",
    "                          \"1) Sample size >= 10k -> PCA, Kernel Approximation \\n\", \n",
    "                          \"2) size < 10k -> PCA, Spectral Embedding, IsoMap, LLE \\n\")\n",
    "                    if sample_size >= 10000 :\n",
    "                        return('Try Randomized PCA first. If it does not work, try Kernel Approximiation') \n",
    "                    else : \n",
    "                        return('Try Randomized PCA first. If it does not work, try Spectral Embedding, IsoMap, or LLE')\n",
    "\n",
    "                else : \n",
    "                    return('Hmm, maybe it is time to imagine the fit structure. Tough luck... ') \n",
    "\n",
    "\n",
    "modelflow(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: ../../../jupyter/DSCI_552/homework-2-hyun95roh/data/CCPP/Folds5x2_pp.xlsx\n",
      "Could not find a suitable delimiter for ../../../jupyter/DSCI_552/homework-2-hyun95roh/data/CCPP/Folds5x2_pp.xlsx\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0:          AT      V       AP     RH      PE\n",
       " 0     14.96  41.76  1024.07  73.17  463.26\n",
       " 1     25.18  62.96  1020.04  59.08  444.37\n",
       " 2      5.11  39.40  1012.16  92.14  488.56\n",
       " 3     20.86  57.32  1010.24  76.64  446.48\n",
       " 4     10.82  37.50  1009.23  96.62  473.90\n",
       " ...     ...    ...      ...    ...     ...\n",
       " 9563  16.65  49.69  1014.01  91.00  460.03\n",
       " 9564  13.19  39.18  1023.67  66.78  469.62\n",
       " 9565  31.32  74.33  1012.92  36.48  429.57\n",
       " 9566  24.48  69.45  1013.86  62.39  435.74\n",
       " 9567  21.60  62.52  1017.23  67.87  453.28\n",
       " \n",
       " [9568 rows x 5 columns]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "def read_multi_extension(path:list ):  \n",
    "    directories = path \n",
    "    data_dic = {i:None for i in range(len(path))} \n",
    "    key = 0 \n",
    "    for directory in directories:\n",
    "        delim = check_delimiters(directory)\n",
    "        extension = directory[directory.rfind('.')+1:]\n",
    "        if extension in ['xlsx','xls','xlsb','xlsm']: \n",
    "            extension = 'excel' \n",
    "            data_dic[key] = eval(f'pd.read_{extension}(\"{directory}\")')\n",
    "        else: \n",
    "            extension = 'csv'\n",
    "            data_dic[key] = eval(f'pd.read_{extension}(\"{directory}\",delimiter={delim})')\n",
    "        key+= 1   \n",
    "    \n",
    "    return data_dic \n",
    "def check_delimiters(file_path):\n",
    "    delimiters = [',', ';', '\\t', '|']\n",
    "    print(f\"Checking file: {file_path}\")\n",
    "    for delimiter in delimiters:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, delimiter=delimiter)\n",
    "            print(f\"Delimiter '{delimiter}' seems to work. Here are the first few rows:\")\n",
    "            print(df.head())\n",
    "            print(\"\\n\")\n",
    "            return delimiter\n",
    "        except Exception as e:\n",
    "            pass \n",
    "            #print(f\"Delimiter '{delimiter}' did not work.\")\n",
    "    print(f\"Could not find a suitable delimiter for {file_path}\\n\")\n",
    "    return None\n",
    "\n",
    "pth = ['../../../jupyter/DSCI_552/homework-2-hyun95roh/data/CCPP/Folds5x2_pp.xlsx']\n",
    "data_dic = read_multi_extension(pth)\n",
    "data_dic  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: MLmodelflow in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (0.0.4)\n",
      "Collecting MLmodelflow\n",
      "  Downloading https://test-files.pythonhosted.org/packages/29/c8/fcbee3b0c8db6c2bb581547ce39f007e87c4ee8ed9edd2d68469f8a619db/MLmodelflow-0.0.5-py3-none-any.whl.metadata (438 bytes)\n",
      "Requirement already satisfied: pandas in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (from MLmodelflow) (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (from MLmodelflow) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (from pandas->MLmodelflow) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (from pandas->MLmodelflow) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->MLmodelflow) (1.16.0)\n",
      "Downloading https://test-files.pythonhosted.org/packages/29/c8/fcbee3b0c8db6c2bb581547ce39f007e87c4ee8ed9edd2d68469f8a619db/MLmodelflow-0.0.5-py3-none-any.whl (4.3 kB)\n",
      "Installing collected packages: MLmodelflow\n",
      "  Attempting uninstall: MLmodelflow\n",
      "    Found existing installation: MLmodelflow 0.0.4\n",
      "    Uninstalling MLmodelflow-0.0.4:\n",
      "      Successfully uninstalled MLmodelflow-0.0.4\n",
      "Successfully installed MLmodelflow-0.0.5\n"
     ]
    }
   ],
   "source": [
    "pip install -i https://test.pypi.org/simple/ MLmodelflow --upgrade "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking file: ../../../jupyter/DSCI_552/homework-2-hyun95roh/data/CCPP/Folds5x2_pp.xlsx\n",
      "Could not find a suitable delimiter for ../../../jupyter/DSCI_552/homework-2-hyun95roh/data/CCPP/Folds5x2_pp.xlsx\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m pth \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../../jupyter/DSCI_552/homework-2-hyun95roh/data/CCPP/Folds5x2_pp.xlsx\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m      5\u001b[0m my_data \u001b[38;5;241m=\u001b[39m read_multi_extension(pth) \n\u001b[1;32m----> 6\u001b[0m \u001b[43mmodelflow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nht95\\anaconda3\\envs\\pyhton_3_11\\Lib\\site-packages\\MLmodelflow\\main.py:7\u001b[0m, in \u001b[0;36mmodelflow\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmodelflow\u001b[39m(data):\n\u001b[1;32m----> 7\u001b[0m     sample_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m  \n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sample_size \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m50\u001b[39m : \n\u001b[0;32m      9\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mYour sample size looks insufficient. Gather more data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "from MLmodelflow import read_multi_extension\n",
    "from MLmodelflow import modelflow\n",
    "\n",
    "pth = ['../../../jupyter/DSCI_552/homework-2-hyun95roh/data/CCPP/Folds5x2_pp.xlsx']\n",
    "my_data = read_multi_extension(pth) \n",
    "modelflow(my_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: MLmodelflow\n",
      "Version: 0.0.5\n",
      "Summary: Model flow chart on the Scikit-learn\n",
      "Home-page: https://github.com/hyun95roh/ml_Modelflow\n",
      "Author: hyun95roh\n",
      "Author-email: hroh@usc.edu\n",
      "License: MIT\n",
      "Location: c:\\Users\\nht95\\anaconda3\\envs\\pyhton_3_11\\Lib\\site-packages\n",
      "Requires: numpy, pandas\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show MLmodelflow"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhton_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
