{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](./ml_map.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excel\n",
      "For predicting categorical variable, there are two branches: Clustering | Classification \n",
      "For clustering : \n",
      " If you have predefined # of cluster: \n",
      "  1) large sample size >= 100k -> KMeans, Spectral, GMM \n",
      "  2) size <100k -> MiniBatch-Kmeans \n",
      " If you don't have predefined # of cluster:\n",
      "   1) size >= 100k -> No recommendable model. You should find the fit model by yourself. \n",
      " 2) size < 100k -> MeanShift, VBGMM \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Try MiniBatch Kmeans clustering'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "# Read data \n",
    "directory = '../../jupyter/DSCI_552/homework-2-hyun95roh/data/CCPP/Folds5x2_pp.xlsx'\n",
    "extension = directory[directory.rfind('.')+1:]\n",
    "if extension in ['xlsx','xls','xlsb','xlsm']: \n",
    "    extension = 'excel' \n",
    "print(extension)\n",
    "read_data = eval(f'pd.read_{extension}(\"{directory}\")') \n",
    "\n",
    "\n",
    "def modelflow(data):\n",
    "    sample_size = len(data)  \n",
    "    if sample_size <50 : \n",
    "        return('Your sample size looks insufficient. Gather more data')\n",
    "    else: \n",
    "        response = input(\"Enter 'Y' either 'N': Are you predicting categorical variable?\")\n",
    "        if response.upper() in ['Y','YES'] :\n",
    "            print(\"For predicting categorical variable, there are two branches: Clustering | Classification \")\n",
    "\n",
    "            response_a1 = input(\"Enter 'Y'or 'N': Do you have labeled response?\" ) \n",
    "            #  Y:Classification \n",
    "            if response_a1.upper() in ['Y','YES'] : \n",
    "                print(\"For classification : \\n\" ,\n",
    "                      \"1) large sample size >= 100k -> SGD \\n\", \n",
    "                      \"2) sample size < 100k -> SVC, NaiveBayes, KNN \\n\") \n",
    "                if sample_size >= 100000 :\n",
    "                    #SGD classificer -> Kernel Approximation  \n",
    "                    return(\"Try Stochastic Gradient Descent(SGD) classifier. If it still not working, try Kernel Approximation\")\n",
    "                else : \n",
    "                    #Linear SVC  -> (text)Naive Bayes | (non-text) KNN -> SVC or Ensemble \n",
    "                    return(\"Linear Support Vector Classifier(SVC) is recommended. If it does not work and if you are working with text data, try Naive Bayes. If you are not dealing with text data then try KNN classifier. If still does not work well, try SVC or Ensemble classifiers \")\n",
    "            else : # N: Clustering \n",
    "                response_a2 = input(\"Enter 'Y'or 'N': Is Number of categories known?\")   \n",
    "                print(\"For clustering : \\n\", \n",
    "                      \"If you have predefined # of cluster: \\n\",\n",
    "                      \" 1) large sample size >= 100k -> KMeans, Spectral, GMM \\n\" ,\n",
    "                      \" 2) size <100k -> MiniBatch-Kmeans \\n\",\n",
    "                      \"If you don't have predefined # of cluster:\\n \",\n",
    "                      \" 1) size >= 100k -> No recommendable model. You should find the fit model by yourself. \\n\",\n",
    "                      \" 2) size < 100k -> MeanShift, VBGMM \\n\"  )\n",
    "                if response_a2.upper() in ['Y','YES'] :\n",
    "                    if sample_size >=100000: \n",
    "                        \n",
    "                        return('Try Kmeans clustering. If it does not work, try Spectral clustering or GMM')     \n",
    "                    else :\n",
    "                        return('Try MiniBatch Kmeans clustering')\n",
    "                \n",
    "                else : # Case when the # of cluster is not predefined.  \n",
    "                    if sample_size >= 100000: \n",
    "                        return('Tough luck...')\n",
    "                    else: \n",
    "                        return('Try MeanShift or VBGMM.') \n",
    "\n",
    "            \n",
    "        elif response.upper() in ['N','NO'] : \n",
    "            print(\"Now your model is heading to: Regression | Dimension Reduction.\") \n",
    "\n",
    "            response_b1 = input(\"Enter 'Y' or 'N': Are you predicting quantitative values?\") #Y: Regression / N: Dim Reduction\n",
    "            if response_b1.upper() in ['Y','YES']:  \n",
    "                print(\"For regression: \\n\", \n",
    "                      \"1) Sample size >= 100k -> SGD \\n\", \n",
    "                      \"2) size < 100k -> Allow regularization has feature selection effect? \\n\",\n",
    "                        \" Yes --> L1-reg, Elastic net \\n\", \n",
    "                        \" No --> L2-reg, SVR, Ensemble. \\n\")\n",
    "                if sample_size >= 100000: \n",
    "                    return(\"Try SGD regressor\") \n",
    "                else : \n",
    "                    response_b1_a = input(\"Enter 'N' or 'Y': Do you want to allow feature selection through Regularization?\")\n",
    "                    if response_b1_a.upper() in ['Y','YES']: \n",
    "                        return('Try regression with L1(Lasso)-regularization or Elsatic Net.')\n",
    "                    else : \n",
    "                        return('Try regression with L2(Ridge)-regularization or Support Vector Regression(SVR) with linear kernel. If still not working, try Ensemble Regressor or SVR with rbf kernel.')\n",
    "\n",
    "            else : \n",
    "                response_b2 = input(\"Enter 'Y' or 'N': Are you running dimensionality reduction?\")  \n",
    "                if response_b2 in ['Y','YES']: \n",
    "                    print(\"For Dimensionality reduction: \\n\", \n",
    "                          \"1) Sample size >= 10k -> PCA, Kernel Approximation \\n\", \n",
    "                          \"2) size < 10k -> PCA, Spectral Embedding, IsoMap, LLE \\n\")\n",
    "                    if sample_size >= 10000 :\n",
    "                        return('Try Randomized PCA first. If it does not work, try Kernel Approximiation') \n",
    "                    else : \n",
    "                        return('Try Randomized PCA first. If it does not work, try Spectral Embedding, IsoMap, or LLE')\n",
    "\n",
    "                else : \n",
    "                    return('Hmm, maybe it is time to imagine the fit structure. Tough luck... ') \n",
    "\n",
    "\n",
    "modelflow(read_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://test.pypi.org/simple/\n",
      "Collecting ml-modelflow\n",
      "  Downloading https://test-files.pythonhosted.org/packages/3f/e8/5505772eb9e35532b177c26553ef358ae1d59cea3ff5ff68c16e51cc4695/ml_modelflow-0.0.1-py3-none-any.whl.metadata (439 bytes)\n",
      "Requirement already satisfied: pandas in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (from ml-modelflow) (1.5.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (from ml-modelflow) (1.24.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (from pandas->ml-modelflow) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (from pandas->ml-modelflow) (2023.3.post1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nht95\\anaconda3\\envs\\pyhton_3_11\\lib\\site-packages (from python-dateutil>=2.8.1->pandas->ml-modelflow) (1.16.0)\n",
      "Downloading https://test-files.pythonhosted.org/packages/3f/e8/5505772eb9e35532b177c26553ef358ae1d59cea3ff5ff68c16e51cc4695/ml_modelflow-0.0.1-py3-none-any.whl (2.0 kB)\n",
      "Installing collected packages: ml-modelflow\n",
      "Successfully installed ml-modelflow-0.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -i https://test.pypi.org/simple/ ml-modelflow \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'ml_modelflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mml_modelflow\u001b[39;00m \n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'ml_modelflow'"
     ]
    }
   ],
   "source": [
    "import ml_modelflow \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyhton_3_11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
